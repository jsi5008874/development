## Stream

### 레디스의 Stream과 아파치 카프카
Stream은 레디스 5.0에서 새로 추가된 자료 구조로 대용량, 대규모의 메시징 데이터를 빠르게 처리할 수 있도록 설계됐다.

stream은 크게 두 가지 방식으로 활용될 수 있다.
1. 백엔드 개발자들은 stream을 대량의 데이터를 효율적으로 처리하는 플랫폼으로 활용
2. 데이터 엔지니어들은 stream을 여러 생산자가 생성한 데이터를 다양한 소비자가 처리할 수 있는 데이터 저장소 및 중간 큐잉 시스템으로 활용

레디스는 카프카의 영향을 많이 받은 시스템으로 카프카와 비슷한 기능을 갖고 있으며 일부 기능은 카프카보다 뛰어나다.

### 스트림이란?
스트림이란 연속적인 데이터의 흐름, 일정한 데이터 조각의 연속을 의미한다.
![[KakaoTalk_Photo_2025-09-22-15-31-15 001.jpeg|725]]
그림은 10GB의 텍스트 파일을 처리하는 애플리케이션에서 바이트 스트림을 처리하는 과정을 보여준다.
파일 하나는 유한하지만 이를 읽어올 때 애플리케이션은 단어 단위, 줄 단위로 데이터를 잘게 쪼개서 처리하기 때문에
프로그램은 바이트 스트림을 처리하는 것이라고 생각할 수 있다.

끝이 정해지지 않고 계속되는 불규칙한 데이터를 연속으로 반복 처리할 때도 스트림 처리를 한다고 할 수 있다.

6-13의 채팅 프로그램 예시는 채팅을 하는 동안 끝없이 JSON 파일을 처리해야하므로 서버는 JSON 스트림 처리하는 것이다.

![[KakaoTalk_Photo_2025-09-22-15-31-15 002.jpeg|725]]
애플리케이션 내부에서는 서버 간 데이터의 이동이 필요할 수도 있다.
웹 서버에서 받아온 데이터를 분석 서버로 전달하거나 데이터를 이메일 서버로 넘기는 등
서비스 간 데이터 전달 과정 또한 연속적인 데이터의 전달을 의미하기 때문에 이 또한 스트림이라 할 수 있다.

![[KakaoTalk_Photo_2025-09-22-15-41-43 001.jpeg|725]]
그림은 예매 서비스에서의 스트림 데이터 처리에 대한 상황을 나타낸다.

여러 프로듀서가 만든 이벤트는 다양한 프로세스를 거쳐 다양한 소비자에 의해 처리될 수 있다.
웹 서버 이벤트는 데이터베이스에 저장되거나 캐시에 저장될 수 있으며 결제 이벤트는 이메일이나 푸시 등의 서비스로 보낼 수 있다.

이벤트를 스트리밍 방식으로 처리하는 것은 편리하지만 직접 스트리밍 플랫폼을 구축하는 것은 어려울 수 있다.
카프카나 레디스 Stream을 활용하면 스트림 데이터를 더 쉽고 정확하게 처리할 수 있다.

### 데이터의 저장
**메시지 저장과 식별**
![[KakaoTalk_Photo_2025-09-22-15-41-44 002.jpeg|725]]
카프카에서 스트림 데이터는 토픽이라는 개념에 저장된다.
토픽은 각각의 분리된 스트림을 뜻하며 같은 데이터를 관리하는 하나의 그룹을 의미한다.

레디스에서는 하나의 stream 자료 구조가 하나의 stream을 의미한다.

카프카에서 각 메시지는 0부터 시작해 증가하는 시퀀스 넘버로 식별할 수 있는데 이때 시퀀스 넘버는 토픽 내의 파티션 안에서만
유니크하게 증가하기 때문에 토픽이 1개 이상의 파티션을 갖는다면 메시지는 하나의 토픽 내에서 유니크하게 식별되지 않는다.

레디스 스트림에서 각 메시지는 시간과 관련된 유니크한 ID를 가지며 이 값은 중복되지 않는다.
```
<millisecondsTime>-<sequenceNumber>
>> ID를 이루는 요소
>> 밀리세컨드 파트는 실제 스트림에 저장될 시점의 레디스 노드 로컬 시간
>> 시퀀스 파트는 같은 밀리세컨드에 저장된 데이터의 순서를 의미(64bit 크기)
```
이 ID 값이 곧 시간을 의미하기 때문에 시간을 이용해 특정 데이터를 검색할 수 있다.

**스트림 생성과 데이터 입력**
카프카에서 생성자는 데이터를 토픽에 푸시하며 소비자는 토픽에서 데이터를 읽는다.
카프카에서는 데이터를 저장하기 위해 토픽을 먼저 생성한 뒤 프로듀서를 이용해 메시지를 보낼 수 있다.
```
-- 토픽 생성
$ kafka-topics --zookeeper 127.0.0.1:6000 --topic email --create partitions
1 --replication-factor 1

-- 데이터 생성
$ kafka-console-consumer --brokers-list 127.0.0.1:7000 --topic Email
> "I am first email"
```

레디스에서는 따로 스트림을 생성하는 과정은 필요하지 않으며 XADD 커맨드를 이용해 새로운 이름의 스트림에 데이터를 저장하면 된다.
```
XADD Email * subject "first" body "hello?"
"1659114481311-0"
>> Email이라는 이름의 스트림이 생성 만약 같은 이름의 스트림이 기존에 존재 했다면 추가됨
>> * 필드는 저장되는 데이터의 ID를 의미하며 *을 사용하면 레디스에서 자동 생성되는 타임스탬프를 ID로 사용하겠다는 뜻
>>   반환된 값("1659....")은 저장되는 데이터의 ID
```
메시지는 키-값 쌍으로 저장되며 위의 예제에서 subject라는 키에 "first"를 body라는 키에 "hello?"를 저장한다.
데이터는 hash 자료 구조처럼 필드-값 쌍으ㅜ로 저장되므로 각 메시지마다 유동적인 데이터를 저장 할 수 있다.

만약 자동으로 생성되는 ID가 아니라 서비스에서 기존에 사용하던 ID를 사용하고 싶다면
```
XADD mystream 0-1 "hello" "world"
0-1

XADD mystream 0-2 "hi" "redis"
0-2
>> ID를 입력하는 필드에 *이 아니라 직접 ID 값을 지정하면 된다.
>> 최소 ID 값은 0-1이며 이후 저장되는 메시지는 전에 저장됐던 ID 값보다 작을 수 없다.
```

**데이터의 조회**
카프카와 레디스 스트림에서 데이터 저장방식은 비슷하지만 데이터를 읽는 방식에는 차이가 존재한다.

카프카에서 소비자는 특정 토픽을 실시간으로 리스닝하며 기본적으로 리스닝을 시작한 시점부터 토픽에 저장되는 메시지를 반환 받도록 동작
소비자는 더 이상 토픽에서 읽어올 데이터가 없으면 새로운 이벤트가 토픽에 들어올 때까지 계속 리스닝하면서 대기한다.
```
$ kafka-console-producer --bootstrap-server 127.0.0.1:7000 --topic email
--from-beginning >> 카프카에 저장돼 있는 모든 데이터를 처음부터 읽겠다는 옵션
> "I am first email"
> "I am second email"
```

레디스 스트림에서는 데이터를 두 가지 방식으로 읽어올 수 있다.
첫 번째는 카프카처럼 실시간으로 처리되는 데이터를 리스닝하는 방법
두 번째는 ID를 이용해 필요한 데이터를 검색하는 방법

```
실시간 리스닝 방식
XREAD [COUNT count](읽을 메시지 수 제한, 선택적) [BLOCK milliseconds](대기 시간, 선택적) 
STREAMS(스트림 키 지정, 필수) key [key ...] ID(스트림에서 읽기 시작할 위치, 필수) [ID ...]

XREAD BLOCK 0 STREAMS Email 0
>>BLOCK 0은 가져올 데이터가 없더라도 연결을 끊지 말고 계속 리스닝
>>STREAMS Email 0은 Email이라는 스트림에 저장된 데이터중 ID가 0보다 큰 값을 읽어오라는 의미

만약 커맨드를 실행한 이후의 메시지만을 가져오고 싶다면 0 대신 특수 ID인 $를 입력


특정한 데이터 조회
XRANGE key start end [COUNT count]
>> ID를 이용해 원하는 시간대의 데이터를 조회
>> 스트림에 저장된 ID 중 가장 작은 ID 값을 지정하고 싶을 때는 -를 제일 마지막 ID는 +를 사용한다.
XRANGE Email - +
>> Email 키에 저장된 전체를 조회
>> XRANGE는 XREAD와 달리 조회한 시점에 저장된 데이터를 반환한다.
>> XREAD는 신규로 들어온 데이터도 계속 반환해준다는 차이점이 있다.

XREVRANGE key end start [COUNT count]
>> 역순으로 조회
```

**소비자와 소비자 그룹**
같은 데이터를 여러 소비자에게 전달하는 것을 팬아웃(fan-out)이라 한다.
카프카에서는 같은 토픽을 여러 개의 소비자가 읽어가게 함으로써 간단하게 팬아웃할 수 있다.
![[KakaoTalk_Photo_2025-09-22-17-06-07.jpeg|800]]
Email이라는 토픽에 3개의 소비자가 연결된 구조
여러 소비자가 저장된 똑같은 데이터를 읽어간다.

레디스 스트림에서도 XREAD 커맨드를 여러 소비자가 수행한다면 팬아웃이 가능하다.
하지만 만약 같은 데이터를 여러 소비자가 나눠서 가져가기 위해서는 어떻게 해야 할까?
같은 역할을 하는 여러 개의 소비자를 이용해 메시지를 병렬 처리함으로써 서비스의 처리 성능을 높일 수 있다.

스트림을 이용해 여러 소비자를 한 번에 여러 이벤트를 병렬적으로 처리되도록 구성할 수 있다.
이때 처리되는 메시지의 순서가 보장돼야 하는 경우와 그렇지 않은 경우에 대해 생각해보자
```
티켓 판매 서비스에서는 고객이 티켓을 결제할 때 카드의 유효성 검사나 사용자 잔고 확인 같은 선행 작업 후에 결제 프로세스가 진행되어야해서
이벤트의 순서를 보장하는 것이 중요하다.
반면 사용자의 회원 가입 이벤트는 각 사용자의 가입 순서를 엄격하게 지키지 않아도 된다.
```
레디스 스트림에서는 데이터가 저장될 때마다 고유한 ID를 부여받아 순서대로 저장된다.
따라서 소비자에게 데이터가 전달될 때 그 순서는 항상 보장된다.

반면 카프카에서 유니크 키는 파티션 내에서만 보장되기 때문에 소비자가 여러 파티션에서 토픽을 읽어갈 때 순서를 보장할 수 없다.
메시지는 토픽에 저장될 때 해시함수에 의해 파티션에 랜덤하게 분배되며 소비자가 토픽에서 데이터를 소비할 때는 파티션의 존재를 알지 못한다.
그리고 토픽 내의 전체 파티션에서 데이터를 읽어와 순서가 보장되지 않는다.

따라서 카프카에서 메시지 순서가 보장되도록 데이터를 처리하기 위해서는 소비자 그룹을 사용해야 한다.

**소비자 그룹**
카프카에서 소비자 그룹에 여러 소비자를 추가할 수 있으며 이때 소비자는 토픽 내의 파티션과 일대일로 연결된다.
![[KakaoTalk_Photo_2025-09-22-17-17-09 001.jpeg|775]]
그림은 소비자 그룹이 Email이라는 토픽에 연결된 것을 나타낸다.
이때 이메일 서버 (1)은 파티션2에 연결됐다. 파티션 내부에서는 메시지의 순서가 보장되기 때문에 서버 (1)에서 데이터를 읽을 때에는 순서가 보장된다.

![[KakaoTalk_Photo_2025-09-22-17-17-09 002.jpeg|775]]
레디스 스트림에서도 소비자 그룹이라는 개념이 존재하지만 카프카와는 다르다.
레디스 스트림은 카프카와 달리 메시지 전달 순서를 신경쓰지 않아도 되기 때문이다.
그래서 소비자 그룹 내의 한 소비자는 다른 소비자가 아직 읽지 않은 데이터만을 읽어간다.

이메일 서버 (2)가 129-0이라는 ID의 메시지를 읽어 갔다면 다른 이베일 서버는 읽지 않은 데이터만 가져간다.
각 요청 시마다 소비자는 스트림에서 차례대로 데이터를 가져온다.

레디스 스트림에서 소비자 그룹을 생성하려면 XGROUP 커맨드를 사용한다.
```
XGROUP CREATE Email EmailServiceGroup $
>> Email 스트림을 읽어가는 EmailServiceGroup이라는 소비자 그룹을 생성
>> $은 현 시점 이후부터 리스닝하겠다는 의미
```

소비자 그룹을 이용해 데이터를 읽고 싶다면 XREADGROUP 커맨드를 사용한다.
```
XREADGROUP GROUP EmailServiceGroup emailService1 COUNT 1 STREAMS Email >
>> EmailServiceGroup에 속한 emailService1이라는 소비자가 Email 스트림에 있는 1개의 메시지를 읽어오는 커맨드
>> STREAM Eamil >이 의미하는 것은 Email이라는 스트림에서 다른 소비자에게 전달되지 않았던 새로운 메시지를 전달하라는 의미
>> 만약 0 또는 다른 숫자 ID를 입력할 경우 새로운 메시지를 확인하는 것이 아닌 입력한 ID보다 큰 ID 중 대기 list에 속하던 메시지를 반환
```

소비자는 처음 언급될 때 자동으로 생성되며 명시적으로 생성할 필요는 없다.
XREAD GROUP을 사용하면 여러 스트림 데이터를 동시에 읽어올 수 있지만 스트림에 동일한 이름을 가진 소비자 그룹을 먼저 생성해야 한다.

XREAD GROUP을 사용해 스트림 데이터를 읽어올 때 읽어오는 동작 자체가 소비자 그룹에 영향을 미치기 때문에 일종의 쓰기 커맨드로 생각해야 한다.
그렇기 때문에 이 커맨드는 마스터에서만 호출할 수 있다.

레디스 스트림에서 소비자 그룹은 스트림의 상태를 나타내는 개념으로 간주된다.
이렇게 생각하면 보류된 메시지(pending message)의 관리 방식과 새로운 메시지를 요청하는 소비자가 매번 
새로운 메시지의 ID를 할당받을 수 있는 방법을 이해하기 쉬워질 것이다.
게다가 하나의 스트림이 여러 개의 소비자 그룹을 가질 수 있다는 사실 또한 명확하게 이해할 수 있을 것이다.

부하 분산의 관점에서 카프카와 비교해서 생각해보자.
카프카가 파티션이라는 개념을 이용해 소비자의 부하 분산을 관리한다면 레디스의 스트림은 소비자 그룹이라는 개념을 이용해 데이터를 분산 시킬 수 있다.

스트림과 소비자 그룹은 독립적으로 동작할 수 있다.
Email이라는 스트림 메시지를 읽어가기 위한 소비자 그룹은 다수 존재할 수 있으로 각각 독립적으로 동작한다.
소비자 그룹 1의 소비자가 a라는 메시지를 읽었다면 같은 그룹에서는 그 메시지를 다시 읽을 수 없지만
다른 그룹 또는 다른 일반 소비자는 해당 메시지를 읽을 수 있다.
하나의 소비자 그룹에서 여러 개의 스트림을 리스닝하는 것도 가능하다.

```
XGROUP CREATE Email bigroup 0
XGROUP CREATE Push bigroup 0

XREADGROUP bigroup BI1 COUNT 2 STREAMS Email PUSH > >

XGROUP 커맨드를 이용해 각 스트림에 bigroup이라는 그룹을 먼저 생성한 뒤
XREADGROUP 커맨드를 이용해서 데이터를 읽으면 bigroup은 Email과 Push 2개의 스트림을 리스닝할 수 있다.
```

![[KakaoTalk_Photo_2025-09-22-19-54-10 001.jpeg|775]]
그림은 스트림 데이터가 여러 소비자 그룹에 의해 어떻게 처리되는지 나타내는 그림이다.
Email과 Push 두 가지 스트림은 실시간 데이터가 쌓인다.
EmailServiceGroup의 각 이메일 서버들은 Email 서비스의 메시지를 읽어가며
NotificationServiceGroup은 Email과 Push 2개 스트림에서 모두 데이터를 읽어가고 있다.
BI 서비스는 그룹이 아닌 일반적인 소비자로서 데이터를 읽어가고 있으며 각 스트림 데이터는 정렬돼 전달된다.

**ACK와 보류 리스트**
여러 서비스가 메시지 브로커를 이용해 데이터를 처리할 때 예상치 못한 장애로 인해 시스템이 종료됐을 경우 이를 처리할 수 있는 기능이 필요하다.
메시지 브로커는 각 소비자에게 어떤 메시지까지 전달 됐고 전달된 메시지의 처리 유무를 인지하고 있어야 한다.

레디스 스트림에서는 소비자 그룹에 속한 소비자가 메시지를 읽어가면 각 소비자별로 읽어간 메시지에 대한 리스트를 새로 생성하며
마지막으로 읽어간 데이터의 ID로 last_delivered_id 값을 업데이트 한다.
이 값은 해당 소비자 그룹에 마지막으로 전달한 ID가 무엇인지를 파악해 동일한 메시지를 중복으로 전달하지 않기 위해 사용된다.
![[KakaoTalk_Photo_2025-09-22-19-54-10 002.jpeg|775]]
그림에서 이메일 서비스 1이라는 소비자가 2개의 메시지를 가져갔고 2가 1개를 가져갔다.
이때 레디스 스트림은 소비자별로 보류 리스트를 만들어서 어떤 소비자가 어떤 데이터를 읽어갔는지 인지하고 있다.
![[KakaoTalk_Photo_2025-09-22-20-07-36.jpeg|775]]
만약 이메일 서비스 2가 스트림에게 데이터가 처리됐다는 뜻의 ACK를 보내면
레디스 스트림은 이메일 서비스 2의 보류 리스트에서 ACK 받은 메시지를 삭제한다.
이렇게 보류 리스트를 통해 소비자가 처리한 데이터를 파악할 수 있다.

XREADGROUP을 이용해 소비자 그룹 형태로 데이터를 읽었을 때
데이터 처리가 완료된 후에 애플리케이션에서 XACK를 주기적으로 전송하는 작업이 필요하다.

현재 소비자 그룹에서 보류 중인 리스트가 있는지 확인하려면
```
XPENDING <key> <groupname> [<start-id> <end-id> <count> [<consumer-name>]]
ex)
XPENDING Email EmailServiceGroup
1) (integer) 9
2) "165911....-0"
3) "165917....-0"
4) 1) 1) "es1"
      2) "1"
....
>> 반환되는 첫 번째 값은 현재 소비자 그룹에서 ACK를 받지 못해 보류중인 메시지의 개수
>> 두 번째 세 번째 값은 각각 보류중인 메시지 ID의 최솟값과 최댓 값이다.
>> 그 뒤로는 각 소비자별로 보류중인 리스트가 몇 개 있는지 알려준다.
```

XACK를 이용해 데이터가 처리됐음을 알려줄 수 있다.
```
XACK Email EmailServiceGroup 165911....-0
(integer) 1
>> Email 스트림의 EmailServiceGroup에 속한 소비자가 165911...-0 ID의 메시지를 처리했다는 의미
```

카프카도 레디스 스트림과 비슷하게 파티션별 오프셋을 관리한다.
```
카프카는 내부적으로 __consumer_offsets라는 토픽에 데이터를 기록
소비자가 지정된 토픽의 특정 파티션의 메시지를 읽으면 소비자 그룹, 토픽, 파티션 내용이 통합돼 저장된다.
소비자 그룹은 __consumer_offsets 토픽에 기록된 정보를 이용해 내부 소비자가 어디까지 읽었는지 추적할 수 있다.
카프카에서 오프셋은 소비자가 마지막으로 읽은 위치가 아니라 다음으로 읽어야 할 위치를 기록한다.
```
![[KakaoTalk_Photo_2025-09-22-20-23-23 001.jpeg|700]]
그림에서 파티션 0의 오프셋은 2번 인덱스를 가리키고 있다.
파티션 0에 연결된 이메일 서버 3은 다음에 2번 인덱스의 메시지부터 읽으면 된다.

**레디스 스트림에서의 at most once vs at least once vs exactly once**
메시징 시스템에서는 세 가지의 메시지 보증 전략을 갖추고 있다.

1. at most once : 메시지를 최소 한번만 보내는 것을 의미
	소비자는 메시지를 받자마자 실제 처리하기 전에 먼저 ACK를 전송
	속도는 향상되지만 실제로 처리되지 않은 경우 데이터 손실 위험성이 있음
![[KakaoTalk_Photo_2025-09-22-20-23-23 002.jpeg|700]]
2. at least once : 소비자는 받은 메시지를 모두 처리한 뒤 ACK 전송
	ACK 전송이 지연돼 실제로 메시지 처리가 됐지만 ACK를 전송하기 전에 소비자가 종료되는 상황이 발생할 수 있음
	이럴 경우 보류 리스트에 처리된 메시지도 남아 있기 때문에 이미 처리한 메시지를 한번 더 처리하는 상황이 발생할 수 있다.
3. exactly once : 모든 메시지가 무조건 한 번씩 전송되는것을 보장
	이 방식으로 전송하고 싶다면 레디스의 set 등의 추가 자료 구조를 이용해 이미 처리된 메시지인지 아닌지 확인하는 과정이 더 필요해진다.

**메시지의 재할당**
만약 소비자가 서버에 장애가 발생해 복구되지 않는다면 해당 소비자가 처리하던 보류 중인 메시지들은 다른 소비자가 대신 처리해야한다.
XCLAIM 커맨드를 사용하면 다른 소비자에게 메시지를 할당할 수 있다.
```
XCLAIM <key> <group> <consumer> <min-idle-time> <ID-1> <ID-1> .... <ID-N>
>> min-idle-time으로 최소 대기 시간을 지정
>> 이는 메시지가 보류 상태로 머무른 시간이 최소 대기 시간을 초과한 경우에만 소유권을 이전해서 같은 메시지가 중복 할당되는것을 방지

ex)
EmailService 1: XCLAIM EMAIL EmailServiceGroup EmailService3 3600000
162656....-0
EmailService 2: XCLAIM EMAIL EmailServiceGroup EmailService3 3600000
162656....-0
>> EmailService3이라는 소비자에게 문제가 생겨서 이 소비자가 처리하던 메시지를 1, 2에게 소유권을 넘기는 상황
>> 2개의 소비자가 모두 보류중인 메시지에 XCLAIM 커맨드를 실행했지만 예시처럼 1번이 먼저 실행되면 보류 시간이 즉시 0으로 재설정됨
>> 2번에서 실행한 XCLAIM 커맨드의 최소 대기 시간보다 메시지의 보류 시간이 짧기 때문에 이 커멘드는 무시되어 중복 메시지 할당을 방지

min-idle-time은 보류된 메시지 즉 3번 서비스의 메시지가 1시간 이상 보류 됐을 때만 적용되도록 하는 옵션이다.
예시에서 1번이 먼저 실행했으므로 3번의 보류된 메시지의 idle-time을 0으로 변경해서 2번의 XCLAIM이 작동하지 않게 만드는 방식이다.
(3번의 보류된 메시지가 0으로 변경되어서 2번의 min-idle-time인 1시간보다 작으므로 2번의 XCLAIM이 미작동)
```

**메시지의 자동 재할당**
소비자가 직접 보류했던 메시지 중 하나를 자동으로 가져와서 처리할 수 있는 XAUTOCLAIM 커맨드
```
XAUTOCLAIM <key> <group> <consumer> <min-idle-time> <start> [COUNT count] [JUSTID]
>> start는 검색을 시작할 메시지 ID, COUNT는 claim 할 메시지 개수, JUSTID는 내용 없이 ID만 반환하는 옵션
>> 할당 대기 중인 다음 메시지의 ID를 반환하는 방식으로 동작하며 반복적 호출 가능
ex)
XAUTICLAIM Email EmailServiceGroup es1 3600000 0-0 count 1
1) "165917....-0"
2) 1) 1) "165911....-0"
      2) 1) "subject"
>> EmailServiceGroup에 최소 보류시간을 만족하는 보류 중인 메시지가 있다면 es1 소비자에게 소유권을 재할당
>> XCLAIM과 다르게 재할당할 메시지를 직접 지정하지 않아도 된다.
>> 첫 번째 반환값은 다음으로 대기 중인 보류 메시지의 ID(다음에 XAUTOCLAIM을 실행하면 가져가게 될 메시지라는 뜻, 현재 반환된 165911...-0의 다음 메시지)
>> 두 번째 반환값은 소유권이 이전된 메시지의 정보
```

**메시지의 수동 재할당**
스트림 내의 메시지는 counter라는 값을 각각 가지고 있다.
XREADGROUP을 이용해 소비자에게 할당하거나 XCLAIM 커맨드를 이용해 재할당할 경우 1씩 증가한다.

하지만 만약 메시지에 문제가 있어서 여러번 할당되기를 반복하면서 counter 값이 증가하게 된다면
counter가 특정 값에 도달했을 때 이 메시지를 특수한 스트림으로 보내 관리자가 추후에 처리할 수 있게 만든다.
이런 메시지를 dead letter라고 부른다.

**stream 상태 확인**
일반적인 메시징 시스템이 그렇듯 어떤 소비자가 활성화됐는지 보류된 메시지는 어떤 건지 어떤 소비자 그룹이 메시지를 처리하고 있는지 등의
상태를 확인하는 커맨드가 없다면 스트림을 관리하기 까다로울 것이다.

XINFO 커맨드를 이용해 스트림의 여러 상태를 확인할 수 있으며 이때 사용할 수 있는 기능은 help 커맨드로 확인할 수 있다.
```
XINFO HELP
1) XINFO <subcommand> [<arg> [value] [opt]...] Subcommands are:
2) consumers <key> <groupname>
3)    SHOW consumers of <groupname>.
4) GROUPS <key>
5)    SHOW the stream consumer groups.
6) STREAM <key> [FULL [COUNT <count>]]
7)    SHOW information about the stream.
8) HELP
9)    Prints this help.

XINFO consumers <stream key> <groupname> 커맨드를 이용해 특정 소비자 그룹에 속한 소비자의 정보를 알 수 있다.
ex)
xinfo consumers email emailservicegroup
1) 1) "name"
   2) "es1"
   3) "pending"
   4) (integer) 1
   5) "idle"
   6) (integer) 650129
>> 소비자 이름, 데이터, 보류 시간 등을 알 수 있다.

XINFO GROUPS <stream key> 커맨드를 이용해 스트림에 속한 전체 소비자 그룹 list를 볼 수 있다.


XINFO STREAM <stream key>를 이용하면 스트림 자체의 정보를 알 수 있다.
```

